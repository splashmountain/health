{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from sklearn import svm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sep():\n",
    "    label_path = 'docclasses_RAtrial.csv'\n",
    "    df=pd.read_csv(label_path)\n",
    "    df1=df.loc[df['truedocumentclass'] == 1]\n",
    "    df0=df.loc[df['truedocumentclass'] == 0]\n",
    "    fn1 = df1['documentname'].tolist()\n",
    "    fn0 = df0['documentname'].tolist()\n",
    "    return fn1, fn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_notes(fn1): # from individual input files\n",
    "    f_path = \"Corpus_Test/*\"\n",
    "    names = glob.glob(f_path) # [...,'Corpus_Test/652742.txt',...]\n",
    "    names.sort()\n",
    "\n",
    "    notes1 = []\n",
    "    id1 = []\n",
    "    notes0 = []\n",
    "    id0 = []\n",
    "    for fi in names:\n",
    "        with open(fi, \"r\") as f:\n",
    "            a = fi[12:] #remove prefix\n",
    "            b = int(a[:-4]) #remove suffix, then b is the id (also doc_name) for each note\n",
    "            note = f.read()\n",
    "            words = note.split()\n",
    "            flat = \" \".join(words)\n",
    "            if b in fn1:\n",
    "                notes1.append(flat)\n",
    "                id1.append(b)\n",
    "            else:\n",
    "                notes0.append(flat)\n",
    "                id0.append(b)\n",
    "    return notes1, notes0, id1, id0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all bleeding notes are read in array named notes1, all non-bleeding notes are read in array named notes1. Let's look at the first bleeding note where bleeding is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn1, fn0 = sep()\n",
    "notes1, notes0, id1, id0 = read_notes(fn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. What is the mean number of words and standard deviation (SD) of that mean for notes labelled as bleeding present? For notes labelled as bleeding absent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_count_stat(notes,nlp):\n",
    "    count_list = []\n",
    "    for note in notes:\n",
    "        doc = nlp(note) \n",
    "        note_tokens = []\n",
    "        for token in doc:\n",
    "            if token.is_punct:\n",
    "                continue\n",
    "            else:\n",
    "                note_tokens.append(token.text)\n",
    "        ct = len(note_tokens)\n",
    "        count_list.append(ct)\n",
    "    count_array = np.array(count_list)\n",
    "    mu = np.mean(count_array)\n",
    "    s = np.std(count_array)\n",
    "    return mu, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228.04109589 679.708749843\n"
     ]
    }
   ],
   "source": [
    "mu1, s1 = word_count_stat(notes1,nlp)\n",
    "print(mu1,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1079.87743191 616.860775617\n"
     ]
    }
   ],
   "source": [
    "mu0, s0 = word_count_stat(notes0,nlp)\n",
    "print(mu0,s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.  What is the mean and SD for the number of times the words “bleed,” “bled,” and “bleeding” appear in notes labelled as bleeding present? For notes labelled as bleeding absent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bleed_count_stat(notes,nlp):\n",
    "    count_list = []\n",
    "    trigger = ['bleed','bled','bleeding']\n",
    "    for note in notes:\n",
    "        doc = nlp(note)\n",
    "        note_tokens = []\n",
    "        for token in doc:\n",
    "            if token.text.lower() in trigger:\n",
    "                note_tokens.append(token.text)\n",
    "        ct = len(note_tokens)\n",
    "        count_list.append(ct)\n",
    "    count_array = np.array(count_list)\n",
    "    mu = np.mean(count_array)\n",
    "    s = np.std(count_array)\n",
    "    return mu, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.36301369863 2.86184186545\n"
     ]
    }
   ],
   "source": [
    "mu1, s1 = bleed_count_stat(notes1,nlp)\n",
    "print(mu1,s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24513618677 0.646921534443\n"
     ]
    }
   ],
   "source": [
    "mu0, s0 = bleed_count_stat(notes0,nlp)\n",
    "print(mu0,s0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. What are the top ten bigrams in notes labelled as bleeding present? For notes labelled as bleeding absent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topn_bigrams_word(notes,nlp,n):\n",
    "    all_sentences = []\n",
    "    all_bigs = []\n",
    "    for note in notes:\n",
    "        doc = nlp(note)\n",
    "        sentences = [sent.text for sent in doc.sents]\n",
    "        all_sentences.extend(sentences) #combine all sentences into one single array\n",
    "        cv_i = CountVectorizer(ngram_range=(2,2)).fit(sentences)\n",
    "        bigs = cv_i.get_feature_names()\n",
    "        all_bigs.append(bigs) # read each note as bigrams into an array\n",
    "\n",
    "    ct_dict = {}\n",
    "    cv = CountVectorizer(ngram_range=(2,2)).fit(all_sentences)\n",
    "    bigs = cv.get_feature_names()\n",
    "    x=cv.fit_transform(all_sentences)\n",
    "    ct_array=sum(x).toarray()[0]\n",
    "    combo = zip(bigs,ct_array)\n",
    "    for bi, c in combo:\n",
    "        ct_dict[bi] = c\n",
    "    sorted_by_value = sorted(ct_dict.items(), key=lambda kv: kv[1], reverse=True)\n",
    "    topn = [x[0] for x in sorted_by_value[:n]]\n",
    "    return topn, all_bigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the patient', 'mg dl', 'in the', 'last name', 'not assessed', 'mg tablet', 'patient was', 'of the', 'sig one', 'to the']\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "topn1, all_bigs1 = topn_bigrams_word(notes1,nlp,n)\n",
    "print(topn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mg dl', 'the patient', 'last name', 'in the', 'mg tablet', 'sig one', 'to the', 'tablet sig', 'tablet po', 'one tablet']\n"
     ]
    }
   ],
   "source": [
    "topn0, all_bigs0 = topn_bigrams_word(notes0,nlp,n)\n",
    "print(topn0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Use scikit learn (or other package) to create a machine learning model to predict bleeding present or bleeding absent for each clinical note. Nothing fancy, just a simple model. What is the sensitivity, specificity, positive predictive value, and negative predictive value for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extracting Features from Notes\n",
    "We have chosen only the most frequently occuring bigrams as the vocabulary list. More specifically, we have chose top $30$ bigrams from bleeding notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def notes_to_tokens(notes,nlp):\n",
    "    tokens = []\n",
    "    for note in notes:\n",
    "        doc = nlp(note) \n",
    "        note_tokens = []\n",
    "        for token in doc:\n",
    "            if token.is_punct:\n",
    "                continue\n",
    "            else:\n",
    "                note_tokens.append(token.text)\n",
    "        tokens.append(note_tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we convert each note into a vector in $R^n$ where $n$ is the number of bigrams and unigrams together in vocabulary list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_voc_dict():\n",
    "    trigger = ['bleed','bled','bleeding']\n",
    "    voc_dict = dict((item, i) for i, item in enumerate(trigger))\n",
    "    return voc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def note_to_idx(note_tokens,voc_dict): \n",
    "    index_list = [voc_dict[token] for token in note_tokens if token in voc_dict]\n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def note_to_vec(note_tokens,voc_dict):\n",
    "    n = len(voc_dict)\n",
    "    result = np.zeros((n,1))\n",
    "    voc_idx = note_to_idx(note_tokens, voc_dict)\n",
    "    for idx in voc_idx:\n",
    "        result[idx] = 1\n",
    "    result = np.reshape(result,n).tolist()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  1.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(660, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prep_X(all_tokens,voc_dict):\n",
    "    X_list=[note_to_vec(x, voc_dict) for x in all_tokens]\n",
    "    df = pd.DataFrame(data=X_list)\n",
    "    X=df.values\n",
    "    return X\n",
    "print(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_y(id1,id0):\n",
    "    idx = id0 + id1\n",
    "    label_path = 'docclasses_RAtrial.csv'\n",
    "    df=pd.read_csv(label_path)\n",
    "    df=df.set_index('documentname')\n",
    "    df1=df.loc[idx]\n",
    "    y=df1.values\n",
    "    m=y.shape[0]\n",
    "    y1=np.reshape(y,m)\n",
    "    return y1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training SVM for Bleed Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(X,y): \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "    #classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "    classifier = svm.SVC(C=50, kernel='rbf', gamma=6)\n",
    "    y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "    return y_test,y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluating the Model Using Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(y_true,y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    sensitivity = tp/(tp+fn+eps)\n",
    "    specificity = tn/(tn+fp+eps)\n",
    "    ppv = tp/(tp+fp+eps)\n",
    "    npv = tn/(tn+fn+eps)\n",
    "    return sensitivity, specificity, ppv, npv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity: 0.292682919691\n",
      "specificity: 0.975806443743\n",
      "positive predictive value: 0.806666661289\n",
      "negative predictive value: 0.806666661289\n"
     ]
    }
   ],
   "source": [
    "n=30\n",
    "eps = 1e-6\n",
    "tokens1=notes_to_tokens(notes1,nlp)\n",
    "tokens0=notes_to_tokens(notes0,nlp)\n",
    "voc_dict=gen_voc_dict()\n",
    "\n",
    "X=prep_X(tokens0+tokens1,voc_dict)\n",
    "y=prep_y(id1,id0)\n",
    "y_test,y_pred=classify(X,y)\n",
    "sensitivity, specificity, ppv, npv=eval(y_test,y_pred)\n",
    "print('sensitivity:', sensitivity)\n",
    "print('specificity:', specificity)\n",
    "print('positive predictive value:', npv)\n",
    "print('negative predictive value:',npv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
